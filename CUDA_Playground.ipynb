{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOFTpC8XIXDBAQlY7H0O/xN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JTStephens18/CUDA_Playground/blob/main/CUDA_Playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "from functools import partial\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from scipy.interpolate import interpn"
      ],
      "metadata": {
        "id": "GxwEpbPgFT1w"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EZAzypRBB7Z9"
      },
      "outputs": [],
      "source": [
        "# Slows things down, but good for development since it stops when there is an error\n",
        "os.environ['CUDA_LAUNCH_BLOCKING']='1'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wurlitzer allows things to be printed from C++/CUDA code in a notebook\n",
        "# Ninja is a build tool required by pytorch to compile C++/CUDA code\n",
        "%pip install -q wurlitzer ninja"
      ],
      "metadata": {
        "id": "BlQlaeGfCH1q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext wurlitzer"
      ],
      "metadata": {
        "id": "6HII8rA5CTix"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "load_inline is a great function that takes in\n",
        "  a list of any of the cuda code strings you want to compile (cuda_sources)\n",
        "  any plain cpp strings you want to compile (cpp_sources)\n",
        "  any functions in the cpp strings you want to make available to pytorch (functions)\n",
        "that compiles it all and turns it into a python module\n",
        "\"\"\"\n",
        "from torch.utils.cpp_extension import load_inline"
      ],
      "metadata": {
        "id": "IZMi4rvwCjit"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cuda(cuda_src, cpp_src, funcs, opt=False, verbose=False):\n",
        "  return load_inline(cuda_sources=[cuda_src], cpp_sources=[cpp_src], functions=funcs,\n",
        "                     extra_cuda_cflags=[\"-O2\"] if opt else [], verbose=verbose, name='inline_ext')"
      ],
      "metadata": {
        "id": "cwFR6a9oC3in"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_begin = r'''\n",
        "#include <torch/extension.h>\n",
        "#include <stdio.h>\n",
        "#include <c10/cuda/CUDAException.h>\n",
        "\n",
        "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
        "// Checks input is contiguous in memory\n",
        "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
        "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
        "\n",
        "// Ceiling division - which we can use to figure out how many blocks we need\n",
        "inline unsigned int cdiv(unsigned int a, unsigned int b) { return (a + b - 1) / b;}\n",
        "'''"
      ],
      "metadata": {
        "id": "kEJhi22hDkVD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Timestep: 33:30 in Getting started with CUDA for Python Programmers\n",
        "  Use __global__ anytime we want to call something from the CPU to run on the GPU\n",
        "  Ex: __global__ void func(int x) {}\n",
        "\n",
        "  To call a CUDA kernel:\n",
        "  func<<<numBlocks, numThreads>>> (\n",
        "    arguments\n",
        "  );\n",
        "\n",
        "  To check for an error call:\n",
        "  C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "  Always call it after calling a kernel to make sure no errors\n",
        "\n",
        "  Must be careful when running a function from a CUDA kernel that it has finished\n",
        "  Can check this by printing a value or .cpu() will wait for the kernel to finish and put it onto cpu\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "q007bqWJIdcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Kernel Code"
      ],
      "metadata": {
        "id": "Uw3oSeXnFWmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Y5UePVFoFrVO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createGramMatrix(points_i, points_j):\n",
        "  \"\"\"\n",
        "    Input: A set of points_i and points_j [batch_size, num_points, num_values] Ex: [16, 2048, 3] and [16, 5000, 3]\n",
        "    Output: A matrix of size [batch_size, num_points_i, num_points_j, 2, 3]\n",
        "            Which represents a set of values at each ij index\n",
        "  \"\"\"\n",
        "  jdx = torch.arange(points_j.shape[1]).unsqueeze(0).repeat(points_i.shape[1], 1)\n",
        "  idx = torch.arange(points_i.shape[1]).unsqueeze(1).repeat(1, points_j.shape[1])\n",
        "  # pairs = torch.cat((points_i[:, idx, :], points_j[:, jdx, :]), dim=3).reshape(points_i.shape[0], points_i.shape[1], points_j.shape[1], 2, -1)\n",
        "  print(idx.shape)\n",
        "  pairs = torch.cat((points_i[:, idx, :], points_j[:, jdx, :]), dim=3)\n",
        "  print(pairs.shape)\n",
        "  return pairs"
      ],
      "metadata": {
        "id": "3VU-6PK7IpEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input1 = torch.randn(2, 2000, 3).to(device)\n",
        "input2 = torch.randn(2, 2000, 3).to(device)\n",
        "# pairsTensor = torch.zeros(4, 2000, 2000, 32).to(device)\n",
        "matrix = createGramMatrix(input1, input2)\n",
        "torch.cuda.empty_cache()\n",
        "# print(matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl7L_CT4FOZv",
        "outputId": "546e8a8e-2e5d-4db0-c4f2-1f10c422d4b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2000, 2000])\n",
            "torch.Size([2, 2000, 2000, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  To modify createGramMatrix to use a CUDA kernel:\n",
        "    First it should not return anything, only modify values in a premade tensor\n",
        "      Could hopefully only create this tensor once for the entire training loop\n",
        "      and just continuously update the values in the tensor.\n",
        "      Ideally would help GPU memory since it is only allocated once\n",
        "    For loop/logic to that concatenates values and adds them into the premade tensor\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "7VREh738d5g4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "pairs = torch.randn(batch_size, 200, 200, 6).to(device)\n",
        "input1 = torch.randn(batch_size, 200, 3).to(device)\n",
        "input2 = torch.randn(batch_size, 200, 3).to(device)"
      ],
      "metadata": {
        "id": "4-mc2tj9ls_e"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pairs[0,0,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFQmW3j7Tckq",
        "outputId": "dfdbe597-6654-47c3-9ce6-44f6e8d1057c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.0756, -1.7596, -0.7277,  0.9198, -0.5163,  0.3295], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pairs[1,12,17, 2])\n",
        "print(input1[1,12,2])\n",
        "print(input2[1,17,2])\n",
        "flat = pairs.flatten()\n",
        "print(flat.shape)\n",
        "\n",
        "flat1 = input1.flatten()\n",
        "flat2 = input2.flatten()\n",
        "\n",
        "# for i in range(pairs.shape[0]):\n",
        "#   for j in range(pairs.shape[1]):\n",
        "#     for k in range(pairs.shape[2]):\n",
        "#       for l in range(pairs.shape[3]):\n",
        "#         idx = i * (pairs.shape[1] * pairs.shape[2] * pairs.shape[3]) +\n",
        "#         j * (pairs.shape[2] * pairs.shape[3]) + k * (pairs.shape[3]) + l\n",
        "\n",
        "\n",
        "i = 1\n",
        "j = 12\n",
        "k = 17\n",
        "l = 2\n",
        "# Formula to calculate index of a flattened tensor given the dimensions of original multidimensional tensor and indexes\n",
        "idx = i * (pairs.shape[1] * pairs.shape[2] * pairs.shape[3]) + j * (pairs.shape[2] * pairs.shape[3]) + k * (pairs.shape[3]) + l\n",
        "input_idx = i * (input1.shape[1] * input1.shape[2]) + j * (input1.shape[2]) + l\n",
        "input_idx2 = i * (input2.shape[1] * input2.shape[2]) + k * (input2.shape[2]) + l\n",
        "print(idx)\n",
        "print(flat[idx])\n",
        "print(input_idx)\n",
        "print(flat1[input_idx])\n",
        "print(input_idx2)\n",
        "print(flat2[input_idx2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8rTT1BzgCaz",
        "outputId": "261cf498-7ae1-4a58-a867-de35428ff793"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-1.0341, device='cuda:0')\n",
            "tensor(1.3791, device='cuda:0')\n",
            "tensor(0.9200, device='cuda:0')\n",
            "torch.Size([9600])\n",
            "3944\n",
            "tensor(-1.0341, device='cuda:0')\n",
            "98\n",
            "tensor(1.3791, device='cuda:0')\n",
            "113\n",
            "tensor(0.9200, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "pairs[:, :200, :, :3] = input1.unsqueeze(2)\n",
        "pairs[:, :, :200, 3:] = input2.unsqueeze(1)"
      ],
      "metadata": {
        "id": "HNfH7q_SVDZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f334090f-4ca0-4efa-f42c-0b838c6ddeea"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 8.69 ms, sys: 2.99 ms, total: 11.7 ms\n",
            "Wall time: 15.6 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(pairs.shape)\n",
        "print(pairs[0,0,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQn0eU7LTar6",
        "outputId": "c0cd17eb-024a-4833-adff-bfc7af3381e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([4, 20, 20, 6])\n",
            "tensor([-1.0355, -1.0061,  0.2309,  0.7025,  0.1076,  1.2185], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_src = cuda_begin + r'''\n",
        "\n",
        "#define BATCH 4\n",
        "#define DIM1 200\n",
        "#define DIM2 200\n",
        "#define DIM3 3\n",
        "\n",
        "__global__ void concat_kernel(float* input1, float* input2, float* out, int h, int w, int batch)  {\n",
        "    int r = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int c = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "    if(r>=h || c>= w) return;\n",
        "    for (int i = 0; i < batch; i++) {\n",
        "      for (int j = 0; j < DIM1; j++) {\n",
        "        for (int k = 0; k < DIM2; k++) {\n",
        "          for (int l = 0; l < DIM3; l++) {\n",
        "            int idx = i * (DIM1 * DIM2 * DIM3) + j * (DIM2 * DIM3) + k * (2*DIM3) + l;\n",
        "            int idx2 = i * (DIM1 * DIM2 * DIM3) + j * (DIM2 * DIM3) + k * (2*DIM3) + l+3;\n",
        "            int input_idx_1 = i * (DIM1 * DIM3) + j * (DIM3) + l;\n",
        "            int input_idx_2 = i * (DIM2 * DIM3) + k * (DIM3) + l;\n",
        "            out[idx] = input1[input_idx_1];\n",
        "            out[idx2] = input2[input_idx_2];\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "torch::Tensor concat(torch::Tensor input1, torch::Tensor input2, torch::Tensor output) {\n",
        "  CHECK_INPUT(input1);\n",
        "  CHECK_INPUT(input2);\n",
        "  CHECK_INPUT(output);\n",
        "  int batch = BATCH;\n",
        "  int h = DIM1;\n",
        "  int w = DIM2;\n",
        "  dim3 tpb(16, 16);\n",
        "  dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
        "  concat_kernel<<<blocks, tpb>>>(\n",
        "    input1.data_ptr<float>(), input2.data_ptr<float>(), output.data_ptr<float>(), h,w, batch);\n",
        "  C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "  return output;\n",
        "}\n",
        "'''"
      ],
      "metadata": {
        "id": "16XcwD7GddPF"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpp_src = \"torch::Tensor concat(torch::Tensor input1, torch::Tensor input2, torch::Tensor output);\"\n",
        "\n",
        "module = load_cuda(cuda_src, cpp_src, ['concat'])"
      ],
      "metadata": {
        "id": "vrD7skAUqalG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = torch.zeros(4, 200, 200, 6).contiguous().to(device)\n",
        "input1 = torch.randn(4, 200, 3).contiguous().to(device)\n",
        "input2 = torch.randn(4, 200, 3).contiguous().to(device)"
      ],
      "metadata": {
        "id": "Wj72YrTVq2oh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "res = module.concat(input1.flatten(), input2.flatten(), out.flatten()).cpu()\n",
        "print(res.shape)"
      ],
      "metadata": {
        "id": "WlSKUguVrGpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87886eef-e131-42b8-baa6-f144daa8959e"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([960000])\n",
            "CPU times: user 215 ms, sys: 2.31 ms, total: 217 ms\n",
            "Wall time: 217 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def trilinear_interpolation(query_points, grid):\n",
        "    # Extract the coordinates of the eight surrounding vertices\n",
        "    grid = grid.permute(0,2,3,4,1)\n",
        "    query_points_floor = query_points.floor().long() - 2\n",
        "    # print(query_points_floor.min())\n",
        "    x0, y0, z0 = query_points_floor[:,:,0], query_points_floor[:,:,1], query_points_floor[:,:,2]\n",
        "    x1, y1, z1 = x0 + 1, y0 + 1, z0 + 1\n",
        "\n",
        "    batch_enum = torch.arange(query_points.shape[0]).unsqueeze(1)\n",
        "\n",
        "    # Extract the values at the eight surrounding vertices\n",
        "    # c000 = grid[:, :, x0, y0, z0]\n",
        "    c000 = grid[batch_enum, x0, y0, z0]\n",
        "    c001 = grid[batch_enum, x0, y0, z1]\n",
        "    c010 = grid[batch_enum, x0, y1, z0]\n",
        "    c011 = grid[batch_enum, x0, y1, z1]\n",
        "    c100 = grid[batch_enum, x1, y0, z0]\n",
        "    c101 = grid[batch_enum, x1, y0, z1]\n",
        "    c110 = grid[batch_enum, x1, y1, z0]\n",
        "    c111 = grid[batch_enum, x1, y1, z1]\n",
        "\n",
        "    # print(c000.shape)\n",
        "    # print(c001.shape)\n",
        "    # print(c010.shape)\n",
        "    # print(c011.shape)\n",
        "    # print(c100.shape)\n",
        "    # print(c101.shape)\n",
        "    # print(c110.shape)\n",
        "    # print(c111.shape)\n",
        "\n",
        "    # Compute the interpolation weights and add 1s to match the last dimension of c000 ... c111\n",
        "    u = (query_points[:,:,0] - x0.float()).unsqueeze(-1).expand(query_points.shape[0],query_points.shape[1], grid.shape[4])\n",
        "    v = (query_points[:,:,1] - y0.float()).unsqueeze(-1).expand(query_points.shape[0],query_points.shape[1], grid.shape[4])\n",
        "    w = (query_points[:,:,2] - z0.float()).unsqueeze(-1).expand(query_points.shape[0],query_points.shape[1], grid.shape[4])\n",
        "\n",
        "    # print(u.shape)\n",
        "    # print(v.shape)\n",
        "    # print(w.shape)\n",
        "\n",
        "    # Perform trilinear interpolation\n",
        "    interpolated_value = (1 - u) * (1 - v) * (1 - w) * c000 + \\\n",
        "                         (1 - u) * (1 - v) * w * c001 + \\\n",
        "                         (1 - u) * v * (1 - w) * c010 + \\\n",
        "                         (1 - u) * v * w * c011 + \\\n",
        "                         u * (1 - v) * (1 - w) * c100 + \\\n",
        "                         u * (1 - v) * w * c101 + \\\n",
        "                         u * v * (1 - w) * c110 + \\\n",
        "                         u * v * w * c111\n",
        "    return interpolated_value"
      ],
      "metadata": {
        "id": "hzGZ3GzCFF-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateTheta(x_tilde, x_tilde_prime):\n",
        "  norm = torch.linalg.norm(x_tilde, dim=-1).unsqueeze(3)\n",
        "  print(norm.shape)\n",
        "  norm_prime = torch.linalg.norm(x_tilde_prime, dim=-1).unsqueeze(3)\n",
        "  print(norm_prime.shape)\n",
        "  numerator = torch.linalg.norm(norm_prime * x_tilde - norm * x_tilde_prime, dim=-1)\n",
        "  denominator = torch.linalg.norm(norm_prime * x_tilde + norm * x_tilde_prime, dim=-1)\n",
        "  theta = torch.atan2(numerator, denominator)\n",
        "  return theta"
      ],
      "metadata": {
        "id": "aB47gHx-FH3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateNeuralSpline(x):\n",
        "    # Convert x to float type if it's not already\n",
        "    # x = x.permute(0,1,3,2)\n",
        "    # Reshape x to have the desired shape [points, points, 2, 3]\n",
        "    #x = x.unsqueeze(3)  # Add a singleton dimension to enable broadcasting\n",
        "    # x_tilde = torch.cat((x[..., 0], torch.ones_like(x[..., :0])), dim=-1)\n",
        "    # x_tilde_prime = torch.cat((x[..., 1], torch.ones_like(x[..., :1])), dim=-1)\n",
        "\n",
        "    x_tilde = x[..., 0]  # Extract x_tilde\n",
        "    x_tilde_prime = x[..., 1]  # Extract x_tilde_prime\n",
        "\n",
        "    theta = calculateTheta(x_tilde, x_tilde_prime)\n",
        "    firstTerm = (torch.linalg.norm(x_tilde, dim=-1) * torch.linalg.norm(x_tilde_prime, dim=-1) / np.pi)\n",
        "    secondTerm = (torch.sin(theta) + 2 * (np.pi - theta) * torch.cos(theta))\n",
        "    kernelVal = firstTerm * secondTerm\n",
        "    return kernelVal.squeeze()  # Remove singleton dimensions"
      ],
      "metadata": {
        "id": "9zgDrlN5FJng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculateKernel(points_i, points_j, grid):\n",
        "  # Get features for each point by trilinearly interpolating from output grid\n",
        "  features_i = trilinear_interpolation(points_i, grid)\n",
        "  features_j = trilinear_interpolation(points_j, grid)\n",
        "  # Concat features with points\n",
        "  concat_points_i = torch.cat((points_i, features_i), dim=2)\n",
        "  concat_points_j = torch.cat((points_j, features_j), dim=2)\n",
        "  # Calculate gram matrix\n",
        "  matrix = createGramMatrix(concat_points_i, concat_points_j)\n",
        "  # Pass matrix into calculateNeuralSpline\n",
        "  Kns = calculateNeuralSpline(matrix)\n",
        "  # Return values\n",
        "  return Kns"
      ],
      "metadata": {
        "id": "TiMrCNF-FLOj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f_x(alpha, new_points, original_points, grid):\n",
        "  return alpha * calculateKernel(new_points, original_points, grid)"
      ],
      "metadata": {
        "id": "s51aaYLPFMSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "/* __global__ void concat_kernel(float* input1, float* input2, float* out, int h, int w)  {\n",
        "#     int r = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "#     int c = blockIdx.x*blockDim.x + threadIdx.x;\n",
        "#     if(r>=h || c>= w) return;\n",
        "#     out[:, :h, :, :3] = input1;\n",
        "#     out[:, :, :w, 3:] = input2;\n",
        "*/ }\n",
        "\n",
        " for (int i = 0; i < input1.size(0); i++){\n",
        "      for (int j = 0; j < h; j++) {\n",
        "        for (int k = 0; k < w; k++) {\n",
        "          for (int z = 0; z < 6; z++) {\n",
        "            out[i, j, k, z] = input1[i, j, z];\n",
        "            out[i, j, k, z+3] = input2[i, k, z];\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "'''"
      ],
      "metadata": {
        "id": "K3cm3mauF26v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}