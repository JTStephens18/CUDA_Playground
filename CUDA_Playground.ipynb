{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMDe1O19jTLSwJEAEMpUmPz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JTStephens18/CUDA_Playground/blob/main/CUDA_Playground.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import math\n",
        "from functools import partial\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from scipy.interpolate import interpn"
      ],
      "metadata": {
        "id": "GxwEpbPgFT1w"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EZAzypRBB7Z9"
      },
      "outputs": [],
      "source": [
        "# Slows things down, but good for development since it stops when there is an error\n",
        "os.environ['CUDA_LAUNCH_BLOCKING']='1'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Wurlitzer allows things to be printed from C++/CUDA code in a notebook\n",
        "# Ninja is a build tool required by pytorch to compile C++/CUDA code\n",
        "%pip install -q wurlitzer ninja"
      ],
      "metadata": {
        "id": "BlQlaeGfCH1q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext wurlitzer"
      ],
      "metadata": {
        "id": "6HII8rA5CTix"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "load_inline is a great function that takes in\n",
        "  a list of any of the cuda code strings you want to compile (cuda_sources)\n",
        "  any plain cpp strings you want to compile (cpp_sources)\n",
        "  any functions in the cpp strings you want to make available to pytorch (functions)\n",
        "that compiles it all and turns it into a python module\n",
        "\"\"\"\n",
        "from torch.utils.cpp_extension import load_inline"
      ],
      "metadata": {
        "id": "IZMi4rvwCjit"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_cuda(cuda_src, cpp_src, funcs, opt=False, verbose=False):\n",
        "  return load_inline(cuda_sources=[cuda_src], cpp_sources=[cpp_src], functions=funcs,\n",
        "                     extra_cuda_cflags=[\"-O2\"] if opt else [], verbose=verbose, name='inline_ext')"
      ],
      "metadata": {
        "id": "cwFR6a9oC3in"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_begin = r'''\n",
        "#include <torch/extension.h>\n",
        "#include <stdio.h>\n",
        "#include <c10/cuda/CUDAException.h>\n",
        "\n",
        "#define CHECK_CUDA(x) TORCH_CHECK(x.device().is_cuda(), #x \" must be a CUDA tensor\")\n",
        "// Checks input is contiguous in memory\n",
        "#define CHECK_CONTIGUOUS(x) TORCH_CHECK(x.is_contiguous(), #x \" must be contiguous\")\n",
        "#define CHECK_INPUT(x) CHECK_CUDA(x); CHECK_CONTIGUOUS(x)\n",
        "\n",
        "// Ceiling division - which we can use to figure out how many blocks we need\n",
        "inline unsigned int cdiv(unsigned int a, unsigned int b) { return (a + b - 1) / b;}\n",
        "'''"
      ],
      "metadata": {
        "id": "kEJhi22hDkVD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "  Timestep: 33:30 in Getting started with CUDA for Python Programmers\n",
        "  Use __global__ anytime we want to call something from the CPU to run on the GPU\n",
        "  Ex: __global__ void func(int x) {}\n",
        "\n",
        "  To call a CUDA kernel:\n",
        "  func<<<numBlocks, numThreads>>> (\n",
        "    arguments\n",
        "  );\n",
        "\n",
        "  To check for an error call:\n",
        "  C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "  Always call it after calling a kernel to make sure no errors\n",
        "\n",
        "  Must be careful when running a function from a CUDA kernel that it has finished\n",
        "  Can check this by printing a value or .cpu() will wait for the kernel to finish and put it onto cpu\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "q007bqWJIdcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Kernel Code"
      ],
      "metadata": {
        "id": "Uw3oSeXnFWmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Y5UePVFoFrVO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 4\n",
        "pairs = torch.randn(batch_size, 200, 200, 6).to(device)\n",
        "input1 = torch.randn(batch_size, 200, 3).to(device)\n",
        "input2 = torch.randn(batch_size, 200, 3).to(device)"
      ],
      "metadata": {
        "id": "4-mc2tj9ls_e"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pairs[1,12,17, 2])\n",
        "print(input1[1,12,2])\n",
        "print(input2[1,17,2])\n",
        "flat = pairs.flatten()\n",
        "print(flat.shape)\n",
        "\n",
        "flat1 = input1.flatten()\n",
        "flat2 = input2.flatten()\n",
        "\n",
        "i = 1\n",
        "j = 12\n",
        "k = 17\n",
        "l = 2\n",
        "# Formula to calculate index of a flattened tensor given the dimensions of original multidimensional tensor and indexes\n",
        "idx = i * (pairs.shape[1] * pairs.shape[2] * pairs.shape[3]) + j * (pairs.shape[2] * pairs.shape[3]) + k * (pairs.shape[3]) + l\n",
        "input_idx = i * (input1.shape[1] * input1.shape[2]) + j * (input1.shape[2]) + l\n",
        "input_idx2 = i * (input2.shape[1] * input2.shape[2]) + k * (input2.shape[2]) + l\n",
        "print(idx)\n",
        "print(flat[idx])\n",
        "print(input_idx)\n",
        "print(flat1[input_idx])\n",
        "print(input_idx2)\n",
        "print(flat2[input_idx2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8rTT1BzgCaz",
        "outputId": "261cf498-7ae1-4a58-a867-de35428ff793"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-1.0341, device='cuda:0')\n",
            "tensor(1.3791, device='cuda:0')\n",
            "tensor(0.9200, device='cuda:0')\n",
            "torch.Size([9600])\n",
            "3944\n",
            "tensor(-1.0341, device='cuda:0')\n",
            "98\n",
            "tensor(1.3791, device='cuda:0')\n",
            "113\n",
            "tensor(0.9200, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "pairs[:, :200, :, :3] = input1.unsqueeze(2)\n",
        "pairs[:, :, :200, 3:] = input2.unsqueeze(1)"
      ],
      "metadata": {
        "id": "HNfH7q_SVDZ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f334090f-4ca0-4efa-f42c-0b838c6ddeea"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 8.69 ms, sys: 2.99 ms, total: 11.7 ms\n",
            "Wall time: 15.6 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cuda_src = cuda_begin + r'''\n",
        "\n",
        "#define BATCH 4\n",
        "#define DIM1 200\n",
        "#define DIM2 200\n",
        "#define DIM3 3\n",
        "\n",
        "__global__ void concat_kernel(float* input1, float* input2, float* out, int h, int w, int batch, int channels)  {\n",
        "// Rows\n",
        "    int r = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "// Columns\n",
        "    int c = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if(r>=h || c>=w) return;\n",
        "    for (int i = 0; i < batch; i++) {\n",
        "      for (int j = 0; j < h; j++) {\n",
        "        for (int k = 0; k < w; k++) {\n",
        "          for (int l = 0; l < channels; l++) {\n",
        "// Calculate indexes for flattened tensor based on their indexes in original multidimensions\n",
        "            int idx = i * (h * w * channels) + j * (w * channels) + k * (2*channels) + l;\n",
        "            int idx2 = i * (h * w * channels) + j * (w * channels) + k * (2*channels) + l+3;\n",
        "            int input_idx_1 = i * (h * channels) + j * (channels) + l;\n",
        "            int input_idx_2 = i * (w * channels) + k * (channels) + l;\n",
        "// Assign values\n",
        "            out[idx] = input1[input_idx_1];\n",
        "            out[idx2] = input2[input_idx_2];\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "}\n",
        "\n",
        "torch::Tensor concat(torch::Tensor input1, torch::Tensor input2, torch::Tensor output) {\n",
        "  CHECK_INPUT(input1);\n",
        "  CHECK_INPUT(input2);\n",
        "  CHECK_INPUT(output);\n",
        "// Assign variables for data dimensions\n",
        "  int batch = input1.size(0);\n",
        "  int h = input1.size(1);\n",
        "  int w = input2.size(1);\n",
        "  int channels = input1.size(2);\n",
        "// Flatten tensors after shape values are stored\n",
        "  auto newInput1 = torch::flatten(input1);\n",
        "  auto newInput2 = torch::flatten(input2);\n",
        "  dim3 tpb(16, 16);\n",
        "  dim3 blocks(cdiv(w, tpb.x), cdiv(h, tpb.y));\n",
        "  concat_kernel<<<blocks, tpb>>>(\n",
        "    newInput1.data_ptr<float>(), newInput2.data_ptr<float>(), output.data_ptr<float>(), h,w, batch, channels);\n",
        "  C10_CUDA_KERNEL_LAUNCH_CHECK();\n",
        "  return output;\n",
        "}\n",
        "'''"
      ],
      "metadata": {
        "id": "16XcwD7GddPF"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cpp_src = \"torch::Tensor concat(torch::Tensor input1, torch::Tensor input2, torch::Tensor output);\"\n",
        "\n",
        "module = load_cuda(cuda_src, cpp_src, ['concat'])"
      ],
      "metadata": {
        "id": "vrD7skAUqalG"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = torch.zeros(4, 200, 200, 6).contiguous().to(device)\n",
        "input1 = torch.randn(4, 200, 3).contiguous().to(device)\n",
        "input2 = torch.randn(4, 200, 3).contiguous().to(device)"
      ],
      "metadata": {
        "id": "Wj72YrTVq2oh"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "res = module.concat(input1, input2, out.flatten()).cpu()\n",
        "print(res.shape)"
      ],
      "metadata": {
        "id": "WlSKUguVrGpE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9592d4d-1256-412f-bdb2-e9814b84528a"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([960000])\n",
            "CPU times: user 223 ms, sys: 3.99 ms, total: 227 ms\n",
            "Wall time: 227 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"1st Tensor\", input1[0,0])\n",
        "print(\"2nd Tensor\", input2[0,0])\n",
        "res = res.reshape(4, 200, 200, 2, 3)\n",
        "print(\"Result\", res[0,0,0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpgqEaov2CUK",
        "outputId": "b392591b-2158-4353-de98-83c5734ced5a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1st Tensor tensor([ 1.5131, -0.0942,  0.8795], device='cuda:0')\n",
            "2nd Tensor tensor([ 0.6690, -0.5289,  0.0010], device='cuda:0')\n",
            "Result tensor([[ 1.5131e+00, -9.4231e-02,  8.7950e-01],\n",
            "        [ 6.6897e-01, -5.2892e-01,  1.0203e-03]])\n"
          ]
        }
      ]
    }
  ]
}